{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import importlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pickle import dump\n",
    "import optuna\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow is already installed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "package_name = \"mlflow\"\n",
    "try:\n",
    "    importlib.import_module(package_name)\n",
    "    print(f\"{package_name} is already installed.\")\n",
    "except ModuleNotFoundError:\n",
    "    print(f\"{package_name} not found. Installing...\")\n",
    "    %pip install {package_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('/home/bcthakreda/mlops_zoomcamp/Machine-Learning-ZoomCamp/week1/data/yellow_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('/home/bcthakreda/mlops_zoomcamp/Machine-Learning-ZoomCamp/week1/data/yellow_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_mb(variable):\n",
    "    size_in_bytes = sys.getsizeof(variable)\n",
    "    size_in_mb = size_in_bytes / (1024 * 1024)\n",
    "    return size_in_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_my_list = get_size_mb(train_dicts)\n",
    "size_my_dict = get_size_mb(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of 'my_list': 11.47 MB\n",
      "Size of 'my_dict': 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of 'my_list': {size_my_list:.2f} MB\")\n",
    "print(f\"Size of 'my_dict': {size_my_dict:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/15 19:16:27 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/04/15 19:16:27 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/bcthakreda/mlops_zoomcamp/Machine-Learning-ZoomCamp/week2/mlruns/6', creation_time=1681571957410, experiment_id='6', last_update_time=1681571957410, lifecycle_stage='active', name='nyc-taxi-optuna-randomforest', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-optuna-randomforest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models_dir = \"models\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have a 'write' attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m'\u001b[39m\u001b[39mr2_score\u001b[39m\u001b[39m'\u001b[39m,rSquared)\n\u001b[1;32m     38\u001b[0m model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(models_dir,\u001b[39m'\u001b[39m\u001b[39mrandomForestRegressor.bin\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m dump(randomForestRegressor,model_path)\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have a 'write' attribute"
     ]
    }
   ],
   "source": [
    "\n",
    "with mlflow.start_run(description=\"Running second Random Forest Regressor with specified Hyperparameters and model dump. Added r square as metric as well\"):\n",
    "\n",
    "    mlflow.set_tag(\"developer\", \"bt\")\n",
    "    mlflow.set_tag(\"model\", \"Random Forest Regressor\")\n",
    "    mlflow.set_tag(\"date\", \"2023-04-15\")\n",
    "\n",
    "    mlflow.log_param(\"train data\", \"/home/bcthakreda/mlops_zoomcamp/Machine-Learning-ZoomCamp/week1/data/yellow_tripdata_2021-01.parquet\")\n",
    "    mlflow.log_param(\"test data\", \"/home/bcthakreda/mlops_zoomcamp/Machine-Learning-ZoomCamp/week1/data/yellow_tripdata_2021-02.parquet\")\n",
    "\n",
    "    n_estimators = 50\n",
    "    max_depth = 15\n",
    "    min_samples_split = 5\n",
    "    min_samples_leaf = 5\n",
    "\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
    "    mlflow.log_param(\"min_samples_leaf\", min_samples_leaf)\n",
    "\n",
    "\n",
    "    randomForestRegressor = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    randomForestRegressor.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = randomForestRegressor.predict(X_val)\n",
    "\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    rSquared = r2_score(y_val,y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric('r2_score',rSquared)\n",
    "\n",
    "    model_path = os.path.join(models_dir,'randomForestRegressor.bin')\n",
    "\n",
    "    with open(model_path,\"wb\") as f:\n",
    "        pickle.dump(randomForestRegressor,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_mlflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
