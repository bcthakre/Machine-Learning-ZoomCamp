{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow is already installed.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "package_name = \"mlflow\"\n",
    "try:\n",
    "    importlib.import_module(package_name)\n",
    "    print(f\"{package_name} is already installed.\")\n",
    "except ModuleNotFoundError:\n",
    "    print(f\"{package_name} not found. Installing...\")\n",
    "    %pip install {package_name}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('/home/bcthakreda/mlops_zoomcamp/Machine-Learning-ZoomCamp/week1/data/yellow_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('/home/bcthakreda/mlops_zoomcamp/Machine-Learning-ZoomCamp/week1/data/yellow_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/07 02:49:44 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/04/07 02:49:44 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/bcthakreda/mlops_zoomcamp/Machine-Learning-ZoomCamp/week2/mlruns/2', creation_time=1679093170978, experiment_id='2', last_update_time=1679093170978, lifecycle_stage='active', name='nyc-taxi-exp-2', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-exp-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import dump, load\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "models_dir = \"models\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "with mlflow.start_run(description=\"Adding Artifact as test\"):\n",
    "\n",
    "    mlflow.set_tag(\"developer\", \"bt\")\n",
    "    mlflow.set_tag(\"model\", \"Lasso\")\n",
    "    mlflow.set_tag(\"date\", \"2023-04-04\")\n",
    "\n",
    "    mlflow.log_param(\"train data\", \"/home/bcthakreda/mlops_zoomcamp/Machine-Learning-ZoomCamp/week1/data/yellow_tripdata_2021-01.parquet\")\n",
    "    mlflow.log_param(\"test data\", \"/home/bcthakreda/mlops_zoomcamp/Machine-Learning-ZoomCamp/week1/data/yellow_tripdata_2021-02.parquet\")\n",
    "\n",
    "    alpha = 0.1\n",
    "\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lasso.predict(X_val)\n",
    "\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    model_path = os.path.join(models_dir, \"lasso_reg.bin\")\n",
    "\n",
    "    dump(lasso, model_path)\n",
    "\n",
    "    mlflow.log_artifact(local_path=model_path, artifact_path=\"models_pickle\")\n",
    "\n",
    "    # # Save the model to a temporary file\n",
    "    # with tempfile.NamedTemporaryFile(suffix=\".bin\", delete=False) as temp_file:\n",
    "    #     dump(lasso, temp_file.name)\n",
    "    #     temp_file.flush()\n",
    "\n",
    "    #     # Log the temporary model file as an artifact\n",
    "    #     mlflow.log_artifact(local_path=temp_file.name, artifact_path=\"models_pickle\")\n",
    "\n",
    "    # # Remove the temporary file after logging the artifact\n",
    "    # os.remove(temp_file.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val,label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable auto logging\n",
    "\n",
    "mlflow.xgboost.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:13.85827\n",
      "[1]\tvalidation-rmse:12.78547\n",
      "[2]\tvalidation-rmse:11.82785\n",
      "[3]\tvalidation-rmse:10.97503\n",
      "[4]\tvalidation-rmse:10.21631\n",
      "[5]\tvalidation-rmse:9.54295\n",
      "[6]\tvalidation-rmse:8.94741\n",
      "[7]\tvalidation-rmse:8.42202\n",
      "[8]\tvalidation-rmse:7.95907\n",
      "[9]\tvalidation-rmse:7.55165\n",
      "[10]\tvalidation-rmse:7.19488\n",
      "[11]\tvalidation-rmse:6.88235\n",
      "[12]\tvalidation-rmse:6.61021\n",
      "[13]\tvalidation-rmse:6.37254\n",
      "[14]\tvalidation-rmse:6.16644\n",
      "[15]\tvalidation-rmse:5.98715\n",
      "[16]\tvalidation-rmse:5.83132\n",
      "[17]\tvalidation-rmse:5.69548\n",
      "[18]\tvalidation-rmse:5.57819\n",
      "[19]\tvalidation-rmse:5.47615\n",
      "[20]\tvalidation-rmse:5.38690\n",
      "[21]\tvalidation-rmse:5.30882\n",
      "[22]\tvalidation-rmse:5.24121\n",
      "[23]\tvalidation-rmse:5.18168\n",
      "[24]\tvalidation-rmse:5.12974\n",
      "[25]\tvalidation-rmse:5.08454\n",
      "[26]\tvalidation-rmse:5.04480\n",
      "[27]\tvalidation-rmse:5.00932\n",
      "[28]\tvalidation-rmse:4.97809\n",
      "[29]\tvalidation-rmse:4.94962\n",
      "[30]\tvalidation-rmse:4.92438\n",
      "[31]\tvalidation-rmse:4.90086\n",
      "[32]\tvalidation-rmse:4.88002\n",
      "[33]\tvalidation-rmse:4.86129\n",
      "[34]\tvalidation-rmse:4.84448\n",
      "[35]\tvalidation-rmse:4.82920\n",
      "[36]\tvalidation-rmse:4.81529\n",
      "[37]\tvalidation-rmse:4.80286\n",
      "[38]\tvalidation-rmse:4.79107\n",
      "[39]\tvalidation-rmse:4.78037\n",
      "[40]\tvalidation-rmse:4.77123\n",
      "[41]\tvalidation-rmse:4.76180\n",
      "[42]\tvalidation-rmse:4.75339\n",
      "[43]\tvalidation-rmse:4.74615\n",
      "[44]\tvalidation-rmse:4.73792\n",
      "[45]\tvalidation-rmse:4.73158\n",
      "[46]\tvalidation-rmse:4.72484\n",
      "[47]\tvalidation-rmse:4.71937\n",
      "[48]\tvalidation-rmse:4.71348\n",
      "[49]\tvalidation-rmse:4.70895\n",
      "[50]\tvalidation-rmse:4.70430\n",
      "[51]\tvalidation-rmse:4.70012\n",
      "[52]\tvalidation-rmse:4.69551\n",
      "[53]\tvalidation-rmse:4.69157\n",
      "[54]\tvalidation-rmse:4.68849\n",
      "[55]\tvalidation-rmse:4.68538\n",
      "[56]\tvalidation-rmse:4.68284\n",
      "[57]\tvalidation-rmse:4.67928\n",
      "[58]\tvalidation-rmse:4.67716\n",
      "[59]\tvalidation-rmse:4.67501\n",
      "[60]\tvalidation-rmse:4.67249\n",
      "[61]\tvalidation-rmse:4.67038\n",
      "[62]\tvalidation-rmse:4.66848\n",
      "[63]\tvalidation-rmse:4.66650\n",
      "[64]\tvalidation-rmse:4.66459\n",
      "[65]\tvalidation-rmse:4.66300\n",
      "[66]\tvalidation-rmse:4.66133\n",
      "[67]\tvalidation-rmse:4.65979\n",
      "[68]\tvalidation-rmse:4.65823\n",
      "[69]\tvalidation-rmse:4.65659\n",
      "[70]\tvalidation-rmse:4.65503\n",
      "[71]\tvalidation-rmse:4.65358\n",
      "[72]\tvalidation-rmse:4.65230\n",
      "[73]\tvalidation-rmse:4.65109\n",
      "[74]\tvalidation-rmse:4.64989\n",
      "[75]\tvalidation-rmse:4.64859\n",
      "[76]\tvalidation-rmse:4.64768\n",
      "[77]\tvalidation-rmse:4.64652\n",
      "[78]\tvalidation-rmse:4.64545\n",
      "[79]\tvalidation-rmse:4.64447\n",
      "[80]\tvalidation-rmse:4.64310\n",
      "[81]\tvalidation-rmse:4.64218\n",
      "[82]\tvalidation-rmse:4.64092\n",
      "[83]\tvalidation-rmse:4.64006\n",
      "[84]\tvalidation-rmse:4.63917\n",
      "[85]\tvalidation-rmse:4.63829\n",
      "[86]\tvalidation-rmse:4.63740\n",
      "[87]\tvalidation-rmse:4.63633\n",
      "[88]\tvalidation-rmse:4.63541\n",
      "[89]\tvalidation-rmse:4.63420\n",
      "[90]\tvalidation-rmse:4.63312\n",
      "[91]\tvalidation-rmse:4.63237\n",
      "[92]\tvalidation-rmse:4.63132\n",
      "[93]\tvalidation-rmse:4.63049\n",
      "[94]\tvalidation-rmse:4.62949\n",
      "[95]\tvalidation-rmse:4.62877\n",
      "[96]\tvalidation-rmse:4.62797\n",
      "[97]\tvalidation-rmse:4.62706\n",
      "[98]\tvalidation-rmse:4.62630\n",
      "[99]\tvalidation-rmse:4.62533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcthakreda/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(description=\"Saving the model with mlflow utility and preprocessor\"):\n",
    "\n",
    "    best_params =  {\n",
    "        'learning_rate' : 0.0958,\n",
    "        'max_depth' : 43,\n",
    "        'min_child_weight' : 1.065,\n",
    "        'objective' : 'reg:squarederror',\n",
    "        'reg_alpha' : 0.018,\n",
    "        'reg_lambda' : 0.011,\n",
    "        'seed' : 42\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=100,\n",
    "        evals=[(valid,'validation')],\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    y_pred = booster.predict(valid)\n",
    "\n",
    "    rmse = mean_squared_error(y_val,y_pred,squared=False)\n",
    "    mlflow.log_metric('rmse',rmse)\n",
    "\n",
    "    with open('models/preprocessor.b','wb') as f_out:\n",
    "        pickle.dump(dv,f_out)\n",
    "\n",
    "    mlflow.log_artifact(\"models/preprocessor.b\",artifact_path=\"preprocessor\")\n",
    "\n",
    "    mlflow.xgboost.log_model(booster,artifact_path=\"models_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model =  mlflow.pyfunc.load_model('runs:/cfb3df973e23455d96aba47d03cfe2b0/models_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = mlflow.xgboost.load_model('runs:/cfb3df973e23455d96aba47d03cfe2b0/models_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_model.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.702003,  8.879979, 20.928928, 13.812995,  3.937456, 10.471272,\n",
       "       37.448692, 21.992466, 10.64559 ,  4.125472], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('model','xgboost')\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(valid,'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = mean_squared_error(y_val,y_pred,squared=False)\n",
    "        mlflow.log_metric(\"rmse\",rmse)\n",
    "        mlflow.log_artifact(local_path='models/lin_reg.bin',artifact_path='models_pickle/')\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth',4,100,1)),\n",
    "    'learning_rate' : hp.loguniform('learning_rate',-3,0),\n",
    "    'reg_alpha' : hp.loguniform('reg_alpha',-5,-1),\n",
    "    'reg_lambda' : hp.loguniform('reg_lambda',-6,-1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight',-1,3),\n",
    "    'objective':'reg:linear',\n",
    "    'seed': 43\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR [hyperopt.fmin] job exception: name 'train' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_result \u001b[39m=\u001b[39m fmin(\n\u001b[1;32m      2\u001b[0m     fn\u001b[39m=\u001b[39;49mobjective,\n\u001b[1;32m      3\u001b[0m     space\u001b[39m=\u001b[39;49msearch_space,\n\u001b[1;32m      4\u001b[0m     algo\u001b[39m=\u001b[39;49mtpe\u001b[39m.\u001b[39;49msuggest,\n\u001b[1;32m      5\u001b[0m     max_evals\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     trials\u001b[39m=\u001b[39;49mTrials()\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[1;32m    541\u001b[0m         fn,\n\u001b[1;32m    542\u001b[0m         space,\n\u001b[1;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    556\u001b[0m     )\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[1;32m    672\u001b[0m     fn,\n\u001b[1;32m    673\u001b[0m     space,\n\u001b[1;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    689\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      3\u001b[0m mlflow\u001b[39m.\u001b[39mset_tag(\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mxgboost\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m mlflow\u001b[39m.\u001b[39mlog_params(params)\n\u001b[1;32m      5\u001b[0m booster \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mtrain(\n\u001b[1;32m      6\u001b[0m     params\u001b[39m=\u001b[39mparams,\n\u001b[0;32m----> 7\u001b[0m     dtrain\u001b[39m=\u001b[39mtrain,\n\u001b[1;32m      8\u001b[0m     num_boost_round\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m,\n\u001b[1;32m      9\u001b[0m     evals\u001b[39m=\u001b[39m[(valid,\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m)],\n\u001b[1;32m     10\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m y_pred \u001b[39m=\u001b[39m booster\u001b[39m.\u001b[39mpredict(valid)\n\u001b[1;32m     13\u001b[0m rmse \u001b[39m=\u001b[39m mean_squared_error(y_val,y_pred,squared\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using hyperopt with linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe,fmin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'fit_intercept': hp.choice('fit_intercept', [True, False])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR [hyperopt.fmin] job exception: 'normalize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'normalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_params \u001b[39m=\u001b[39m fmin(\n\u001b[1;32m      2\u001b[0m     fn\u001b[39m=\u001b[39;49mobjective,\n\u001b[1;32m      3\u001b[0m     space\u001b[39m=\u001b[39;49msearch_space,\n\u001b[1;32m      4\u001b[0m     algo\u001b[39m=\u001b[39;49mtpe\u001b[39m.\u001b[39;49msuggest,\n\u001b[1;32m      5\u001b[0m     max_evals\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[34], line 7\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      4\u001b[0m mlflow\u001b[39m.\u001b[39mlog_params(params)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Create and train the linear regression model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model \u001b[39m=\u001b[39m LinearRegression(fit_intercept\u001b[39m=\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mfit_intercept\u001b[39m\u001b[39m'\u001b[39m], normalize\u001b[39m=\u001b[39mparams[\u001b[39m'\u001b[39;49m\u001b[39mnormalize\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      8\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Make predictions on the validation set\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'normalize'"
     ]
    }
   ],
   "source": [
    "best_params = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR [hyperopt.fmin] job exception: 'float' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m         mlflow\u001b[39m.\u001b[39msklearn\u001b[39m.\u001b[39mlog_model(model, \u001b[39m\"\u001b[39m\u001b[39mmodels_lin_reg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m: rmse, \u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m: STATUS_OK}\n\u001b[0;32m---> 24\u001b[0m best \u001b[39m=\u001b[39m fmin(fn\u001b[39m=\u001b[39;49mobjective,space\u001b[39m=\u001b[39;49msearch_space,algo\u001b[39m=\u001b[39;49mtpe\u001b[39m.\u001b[39;49msuggest,max_evals\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m     26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Alpha Value: \u001b[39m\u001b[39m\"\u001b[39m, best[\u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m mlflow\u001b[39m.\u001b[39mstart_run():\n\u001b[1;32m      3\u001b[0m     mlflow\u001b[39m.\u001b[39mset_tag(\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlinear_regression\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     mlflow\u001b[39m.\u001b[39;49mlog_params(params)\n\u001b[1;32m      6\u001b[0m     \u001b[39m# Create and train the linear regression model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     model \u001b[39m=\u001b[39m LinearRegression(fit_intercept\u001b[39m=\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mfit_intercept\u001b[39m\u001b[39m'\u001b[39m], normalize\u001b[39m=\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mnormalize\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment-tracking/lib/python3.9/site-packages/mlflow/tracking/fluent.py:701\u001b[0m, in \u001b[0;36mlog_params\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[39mLog a batch of params for the current run. If no run is active, this method will create a\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[39mnew active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[39m        mlflow.log_params(params)\u001b[39;00m\n\u001b[1;32m    699\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    700\u001b[0m run_id \u001b[39m=\u001b[39m _get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m--> 701\u001b[0m params_arr \u001b[39m=\u001b[39m [Param(key, \u001b[39mstr\u001b[39m(value)) \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39;49mitems()]\n\u001b[1;32m    702\u001b[0m MlflowClient()\u001b[39m.\u001b[39mlog_batch(run_id\u001b[39m=\u001b[39mrun_id, metrics\u001b[39m=\u001b[39m[], params\u001b[39m=\u001b[39mparams_arr, tags\u001b[39m=\u001b[39m[])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('model', 'linear_regression')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Create and train the linear regression model\n",
    "        model = LinearRegression(fit_intercept=params['fit_intercept'])\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Calculate the RMSE\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "        # Log the results with MLflow\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # Save the model\n",
    "        mlflow.sklearn.log_model(model, \"models_lin_reg\")\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "best = fmin(fn=objective,space=search_space,algo=tpe.suggest,max_evals=100)\n",
    "\n",
    "print(\"Best Alpha Value: \", best['alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
